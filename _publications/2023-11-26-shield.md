---
title: "A Probabilistic Design for Practical Homomorphic Majority Voting with Intrinsic Differential Privacy"
collection: publications
permalink: /publication/2023-11-26-shield
excerpt: "BLABLA"
date: 2023-11-26
venue: 'Proceedings of the 11th Workshop on Encrypted Computing & Applied Homomorphic Cryptography'
paperurl: 'https://dl.acm.org/doi/pdf/10.1145/3605759.3625258'
citation: 'Grivet SÃ©bert, A., Zuber, M., Stan, O., Sirdey, R., & Gouy-Pailler, C. (2023, November). A probabilistic design for practical homomorphic majority voting with intrinsic differential privacy. In Proceedings of the 11th Workshop on Encrypted Computing & Applied Homomorphic Cryptography (pp. 47-58).'
---
As machine learning (ML) has become pervasive throughout various fields (industry, healthcare, social networks), privacy concerns regarding the data used for its training have gained a critical importance. In settings where several parties wish to collaboratively train a common model without jeopardizing their sensitive data, the need for a private training protocol is particularly stringent and implies to protect the data against both the model's end-users and the other actors of the training phase. In this context of secure collaborative learning, Differential Privacy (DP) and Fully Homomorphic Encryption (FHE) are two complementary countermeasures of growing interest to thwart privacy attacks in ML systems. Central to many collaborative training protocols, in the line of PATE, is majority voting aggregation. Thus, in this paper, we design SHIELD, a probabilistic approximate majority voting operator which is faster when homomorphically executed than existing approaches based on exact argmax computation over an histogram of votes. As an additional benefit, the inaccuracy of SHIELD is used as a feature to provably enable DP guarantees. Although SHIELD may have other applications, we focus here on one setting and seamlessly integrate it in the SPEED collaborative training framework from [20] to improve its computational efficiency. After thoroughly describing the FHE implementation of our algorithm and its DP analysis, we present experimental results. To the best of our knowledge, it is the first work in which relaxing the accuracy of an algorithm is constructively usable as a degree of freedom to achieve better FHE performances.
